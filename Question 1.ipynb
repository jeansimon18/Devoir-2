{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4df3a1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRDS recommends setting up a .pgpass file.\n",
      "pgpass file created at C:\\Users\\berge\\AppData\\Roaming\\postgresql\\pgpass.conf\n",
      "Created .pgpass file successfully.\n",
      "You can create this file yourself at any time with the create_pgpass_file() function.\n",
      "Loading library list...\n",
      "Done\n",
      "Tickers S&P500 (présents toute la période 2003-2023) : 273\n",
      "Lignes comp_tic_sector : 61550\n",
      "Après merge S&P500 x secteurs : 273\n",
      "Tickers exclus (oil/coal/mines/gold/steel/RE) : 20\n",
      "Tickers restants après filtrage               : 253\n",
      "Tickers sélectionnés : ['PARA' 'FISV' 'AEE' 'PMTCE' 'VFC' 'HD' 'EA' 'SCHW' 'DTE' 'MHP' 'CMCSA'\n",
      " 'EMN' 'HIG' 'ABC' 'GWW' 'TXT' 'SCH' 'IBM' 'AHC' 'EIX' 'ADSK' 'AMGN' 'MMC'\n",
      " 'TAP' 'RTX' 'JPM' 'PRU' 'CSCO' 'ETN' 'VZ' 'CI' 'BFB' 'NTRS' 'ATH' 'COF'\n",
      " 'HSY' 'DOV' 'MO' 'FPL' 'HAS' 'BHGE' 'LTD' 'EBAY' 'FDX' 'ABT' 'CINF' 'PCG'\n",
      " 'WEC' 'PTC' 'ADBE']\n",
      "\n",
      "Fichier Excel créé : sp500_filtered_random50.xlsx\n"
     ]
    }
   ],
   "source": [
    "import wrds\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ============================================================\n",
    "# 0. Connexion WRDS\n",
    "# ============================================================\n",
    "\n",
    "db = wrds.Connection()\n",
    "\n",
    "# ============================================================\n",
    "# 1. Tickers S&P 500 présents TOUTE la période 2003-2023\n",
    "#    via CRSP (actions ordinaires seulement)\n",
    "# ============================================================\n",
    "\n",
    "sp500_crsp = db.raw_sql(\"\"\"\n",
    "    WITH full_members AS (\n",
    "        SELECT\n",
    "            permno,\n",
    "            MIN(start) AS min_start,\n",
    "            MAX(COALESCE(ending, '9999-12-31')) AS max_end\n",
    "        FROM crsp.msp500list\n",
    "        GROUP BY permno\n",
    "        HAVING MIN(start) <= '2003-01-01'\n",
    "           AND MAX(COALESCE(ending, '9999-12-31')) >= '2023-12-31'\n",
    "    )\n",
    "    SELECT DISTINCT\n",
    "        c.permno,\n",
    "        c.tsymbol AS tic\n",
    "    FROM full_members AS f\n",
    "    JOIN crsp.msenames AS c\n",
    "      ON f.permno = c.permno\n",
    "    WHERE c.tsymbol IS NOT NULL\n",
    "      AND c.shrcd IN (10, 11)    -- seulement common shares\n",
    "      AND c.namedt <= '2023-12-31'\n",
    "      AND (c.nameendt >= '2003-01-01' OR c.nameendt IS NULL)\n",
    "\"\"\")\n",
    "\n",
    "sp500_crsp[\"tic\"] = sp500_crsp[\"tic\"].astype(str).str.strip()\n",
    "sp500_tickers = sp500_crsp[\"tic\"].drop_duplicates()\n",
    "\n",
    "print(\"Tickers S&P500 (présents toute la période 2003-2023) :\", len(sp500_tickers))\n",
    "\n",
    "# ============================================================\n",
    "# 2. Secteurs Compustat via comp.secm + comp.company\n",
    "#    - comp.secm : gvkey, tic\n",
    "#    - comp.company : gvkey, gsector, gsubind\n",
    "# ============================================================\n",
    "\n",
    "comp_secm = db.raw_sql(\"\"\"\n",
    "    SELECT DISTINCT\n",
    "        gvkey,\n",
    "        tic\n",
    "    FROM comp.secm\n",
    "    WHERE tic IS NOT NULL\n",
    "\"\"\")\n",
    "comp_secm[\"tic\"] = comp_secm[\"tic\"].astype(str).str.strip()\n",
    "comp_secm[\"gvkey\"] = comp_secm[\"gvkey\"].astype(str).str.strip()\n",
    "\n",
    "comp_company = db.raw_sql(\"\"\"\n",
    "    SELECT\n",
    "        gvkey,\n",
    "        gsector,\n",
    "        gsubind\n",
    "    FROM comp.company\n",
    "    WHERE gsector IS NOT NULL\n",
    "\"\"\")\n",
    "comp_company[\"gvkey\"] = comp_company[\"gvkey\"].astype(str).str.strip()\n",
    "comp_company[\"gsector\"] = comp_company[\"gsector\"].astype(str).str.strip()\n",
    "comp_company[\"gsubind\"] = comp_company[\"gsubind\"].astype(str).str.strip()\n",
    "\n",
    "# Merge pour avoir (tic, gsector, gsubind)\n",
    "comp_tic_sector = comp_secm.merge(comp_company, on=\"gvkey\", how=\"left\")\n",
    "\n",
    "print(\"Lignes comp_tic_sector :\", len(comp_tic_sector))\n",
    "\n",
    "# ============================================================\n",
    "# 3. Merge S&P500 (CRSP) avec les secteurs Compustat\n",
    "# ============================================================\n",
    "\n",
    "merged = sp500_crsp.merge(\n",
    "    comp_tic_sector[[\"tic\", \"gsector\", \"gsubind\"]],\n",
    "    on=\"tic\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "print(\"Après merge S&P500 x secteurs :\", len(merged))\n",
    "\n",
    "# ============================================================\n",
    "# 4. Filtre secteurs fin : exclure\n",
    "#    - Real Estate (gsector=60)\n",
    "#    - Oil / Coal : gsubind ~ 10102*\n",
    "#    - Mines / Gold / Steel / Metals & Mining : gsubind ~ 15104*\n",
    "# ============================================================\n",
    "\n",
    "gsector = merged[\"gsector\"].astype(str)\n",
    "gsubind = merged[\"gsubind\"].astype(str)\n",
    "\n",
    "# Real Estate = tout gsector commençant par \"60\"\n",
    "mask_real_estate = gsector.str.startswith(\"60\")\n",
    "\n",
    "# Oil, Gas & Consumable Fuels (inclut coal) -> 10102xx\n",
    "# Metals & Mining / Gold / Steel -> 15104xx\n",
    "exclude_gsubind_prefixes = (\"10102\", \"15104\")\n",
    "mask_oil_mines_gold_steel = gsubind.str.startswith(exclude_gsubind_prefixes)\n",
    "\n",
    "mask_exclu = mask_real_estate | mask_oil_mines_gold_steel\n",
    "\n",
    "merged_filtered = merged[~mask_exclu].copy()\n",
    "\n",
    "print(\"Tickers exclus (oil/coal/mines/gold/steel/RE) :\", mask_exclu.sum())\n",
    "print(\"Tickers restants après filtrage               :\", merged_filtered[\"tic\"].nunique())\n",
    "\n",
    "tickers_filtered = merged_filtered[\"tic\"].drop_duplicates()\n",
    "\n",
    "# ============================================================\n",
    "# 5. Tirage aléatoire de 50 tickers parmi ceux restants\n",
    "# ============================================================\n",
    "\n",
    "np.random.seed(42)\n",
    "n_tickers = min(50, len(tickers_filtered))\n",
    "tickers_50 = np.random.choice(tickers_filtered, size=n_tickers, replace=False)\n",
    "\n",
    "print(\"Tickers sélectionnés :\", tickers_50)\n",
    "\n",
    "tickers_sql = \"'\" + \"', '\".join(tickers_50) + \"'\"\n",
    "\n",
    "# ============================================================\n",
    "# 6. Données journalières Compustat (secd) pour ces tickers\n",
    "# ============================================================\n",
    "\n",
    "query = f\"\"\"\n",
    "    SELECT\n",
    "        s.tic,\n",
    "        s.datadate,\n",
    "        s.eps,\n",
    "        s.prccd,\n",
    "        s.gvkey\n",
    "    FROM comp_na_daily_all.secd AS s\n",
    "    WHERE s.datadate BETWEEN '2003-01-01' AND '2023-12-31'\n",
    "      AND s.tic IN ({tickers_sql})\n",
    "\"\"\"\n",
    "\n",
    "df = db.raw_sql(query)\n",
    "\n",
    "df[\"datadate\"] = pd.to_datetime(df[\"datadate\"])\n",
    "df = df.sort_values([\"tic\", \"datadate\"])\n",
    "\n",
    "# ============================================================\n",
    "# 7. Nettoyage numérique + P/E instantané\n",
    "# ============================================================\n",
    "\n",
    "df[\"eps\"]   = pd.to_numeric(df[\"eps\"], errors=\"coerce\")\n",
    "df[\"prccd\"] = pd.to_numeric(df[\"prccd\"], errors=\"coerce\")\n",
    "\n",
    "df[\"pe_ratio\"] = np.where(\n",
    "    (df[\"eps\"].notna()) & (df[\"eps\"] > 0),\n",
    "    df[\"prccd\"] / df[\"eps\"],\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 8. Export Excel\n",
    "# ============================================================\n",
    "\n",
    "output_file = \"sp500_filtered_random50.xlsx\"\n",
    "df.to_excel(output_file, index=False)\n",
    "\n",
    "print(\"\\nFichier Excel créé :\", output_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
